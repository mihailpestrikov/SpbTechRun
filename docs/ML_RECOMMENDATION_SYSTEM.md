# Система рекомендаций сопутствующих товаров: ML-архитектура

## Оглавление
1. [Общая концепция](#общая-концепция)
2. [Ключевое понимание: что обучается, а что нет](#ключевое-понимание-что-обучается-а-что-нет)
3. [Подготовка данных](#подготовка-данных)
4. [Холодный старт: как работают рекомендации без фидбека](#холодный-старт-как-работают-рекомендации-без-фидбека)
5. [Система фидбека и накопление данных](#система-фидбека-и-накопление-данных)
6. [Персонализация: как профиль пользователя влияет на рекомендации](#персонализация-как-профиль-пользователя-влияет-на-рекомендации)
7. [Полный алгоритм генерации рекомендаций](#полный-алгоритм-генерации-рекомендаций)
8. [Эволюция системы: от холодного старта к персонализации](#эволюция-системы-от-холодного-старта-к-персонализации)
9. [Опционально: ML-модель ранжирования](#опционально-ml-модель-ранжирования)
10. [Структура данных и таблицы](#структура-данных-и-таблицы)

---

## Общая концепция

Система рекомендаций решает задачу: **для основного товара (например, штукатурки) подобрать сопутствующие товары (шпатели, грунтовки, маяки)**, которые нужны для выполнения ремонтных работ на этапе White Box.

Это НЕ задача "найти похожие товары". Похожие — это другие штукатурки. Сопутствующие — это товары из других категорий, которые используются вместе с основным.

### Почему это сложно

1. **Холодный старт** — в начале нет данных о том, какие товары реально покупают вместе
2. **Семантическая близость ≠ сопутствие** — "штукатурка" и "шпатлёвка" семантически близки, но это не сопутствующие товары, а товары-заменители
3. **Нужна персонализация** — разным пользователям подходят разные рекомендации (по бюджету, брендам, предпочтениям)

### Решение: гибридная система

Комбинируем несколько подходов:
- **Семантический поиск через LLM (Ollama)** — для нахождения релевантных кандидатов
- **Правила категорий** — экспертные знания о том, какие категории сочетаются
- **Статистика фидбека** — накопленные данные от пользователей
- **Профили пользователей** — персональные предпочтения

---

## Ключевое понимание: что обучается, а что нет

Это критически важно для понимания архитектуры.

### Что НЕ меняется (frozen)

| Компонент | Описание | Когда обновляется |
|-----------|----------|-------------------|
| Ollama модель | Генерирует эмбеддинги текста | Никогда — это предобученная модель |
| Эмбеддинги товаров | Векторные представления каждого товара | Только при добавлении новых товаров в каталог |
| FAISS индекс | Индекс для быстрого поиска похожих векторов | Только при изменении каталога |
| Правила категорий | Экспертные знания "штукатурка → шпатель" | Вручную, при необходимости |

### Что МЕНЯЕТСЯ (learning)

| Компонент | Описание | Когда обновляется |
|-----------|----------|-------------------|
| Статистика пар товаров | Счётчики лайков/дизлайков для каждой пары "основной→рекомендованный" | При каждом фидбеке от пользователя |
| Профили пользователей | Предпочтения по категориям, брендам, ценовому диапазону | При каждом фидбеке от этого пользователя |
| ML-модель ранжирования (опционально) | Классификатор для предсказания релевантности | Периодически (раз в сутки) на накопленных данных |

### Главный инсайт

**"Обучение" системы — это НЕ дообучение нейросети.**

Это накопление статистики в базе данных. Ollama остаётся замороженной. Мы просто собираем информацию о том, какие рекомендации пользователи одобряют, и используем эту статистику при ранжировании.

---

## Подготовка данных

### Шаг 1: Парсинг YML-фида

Из XML-файла каталога извлекаем для каждого товара:
- Уникальный идентификатор
- Название товара
- Описание (если есть)
- Категория (и вся иерархия категорий)
- Параметры: бренд, материал, объём, вес и другие характеристики
- Цена

### Шаг 2: Построение текстового представления

Для каждого товара формируем текстовую строку, которая будет передана в LLM для генерации эмбеддинга. Важно включить всю релевантную информацию:

```
"Грунтовка KNAUF Tiefengrund универсальная 10л.
Категория: Грунтовки для внутренних работ.
Применение: для стен, для потолков, для гипсокартона.
Бренд: KNAUF. Объём: 10 литров. Расход: 100 мл/м²."
```

Качество этого текста напрямую влияет на качество эмбеддингов и, следовательно, на качество рекомендаций.

### Шаг 3: Генерация эмбеддингов через Ollama

Для каждого товара отправляем его текстовое представление в Ollama и получаем вектор (эмбеддинг) фиксированной размерности (обычно 768 или 1024 измерения).

Рекомендуемые модели в Ollama:
- `nomic-embed-text` — лёгкая и быстрая, хороший баланс скорость/качество
- `mxbai-embed-large` — более точная, но медленнее

Эта операция выполняется **один раз** при загрузке каталога. Эмбеддинги сохраняются в базу данных.

### Шаг 4: Построение поискового индекса

Все эмбеддинги загружаются в векторный индекс для быстрого поиска ближайших соседей. Варианты:
- **FAISS** (Facebook AI Similarity Search) — стандартное решение, быстрый и надёжный
- **Простая матрица numpy** — для небольших каталогов (до 50k товаров) работает достаточно быстро

---

## Холодный старт: как работают рекомендации без фидбека

В первый день работы системы у нас нет никаких данных о предпочтениях пользователей. Но рекомендации уже должны работать.

### Источник 1: Семантическая близость (Ollama)

Когда пользователь открывает товар X, мы:
1. Берём его эмбеддинг из базы
2. Ищем в FAISS индексе 100 ближайших товаров по cosine similarity
3. Получаем список кандидатов с оценками близости (0 до 1)

**Проблема:** семантически близкие товары — это часто товары-аналоги (другие штукатурки), а не сопутствующие (шпатели).

### Источник 2: Правила категорий (экспертные знания)

Чтобы отфильтровать аналоги и оставить сопутствующие, применяем правила:

1. **Исключаем товары из той же категории** — если основной товар "штукатурка", убираем все другие штукатурки
2. **Оставляем только совместимые категории** — используем справочник, где указано какие категории сочетаются

Пример справочника совместимых категорий для этапа White Box:

| Основная категория | Сопутствующие категории |
|--------------------|------------------------|
| Штукатурки | Шпатели, Правила, Маяки штукатурные, Грунтовки, Миксеры |
| Наливной пол | Грунтовки, Валики игольчатые, Миксеры, Ёмкости для замеса |
| Электропроводка (кабели) | Подрозетники, Гофра, Клеммы, Изолента, Распред. коробки |
| Гипсокартон | Профили, Саморезы, Шуруповёрты, Серпянка, Шпаклёвка |

Эти правила составляются на основе экспертных знаний о ремонте и могут корректироваться.

### Результат холодного старта

На выходе получаем список из ~20-50 кандидатов, которые:
- Семантически связаны с основным товаром (по эмбеддингам)
- Относятся к совместимым категориям (по правилам)
- Отсортированы по оценке семантической близости

Это базовое качество рекомендаций, которое работает с первого дня.

---

## Система фидбека и накопление данных

### Что собираем

При каждой оценке пользователя сохраняем:
- ID пользователя (кто оценил)
- ID основного товара (к какому товару была рекомендация)
- ID рекомендованного товара (что рекомендовали)
- Тип фидбека: положительный ("подошёл") или отрицательный ("не подошёл")
- Время оценки

### Глобальная статистика пар товаров

Из сырых данных фидбека агрегируем статистику для каждой пары "основной товар → рекомендованный товар":

| Основной товар | Рекомендованный | Положительных | Отрицательных | Процент одобрения |
|----------------|-----------------|---------------|---------------|-------------------|
| Штукатурка KNAUF | Шпатель А | 47 | 3 | 94% |
| Штукатурка KNAUF | Шпатель Б | 12 | 28 | 30% |
| Штукатурка KNAUF | Грунтовка X | 89 | 5 | 95% |

### Как статистика влияет на рекомендации

Эти данные превращаются в множитель при ранжировании:

- Пара с 94% одобрения получает множитель ~1.9 (сильно поднимается в выдаче)
- Пара с 30% одобрения получает множитель ~0.6 (опускается вниз или исчезает)
- Пара без статистики получает нейтральный множитель 1.0

Используется байесовское сглаживание, чтобы один случайный лайк не давал 100% и один дизлайк не давал 0%.

### Обновление в реальном времени

При каждом новом фидбеке:
1. Обновляем счётчики в таблице статистики (инкремент положительных или отрицательных)
2. Следующий запрос рекомендаций для этого основного товара уже учтёт новые данные

Нет необходимости в переобучении модели — это простое обновление счётчиков.

---

## Персонализация: как профиль пользователя влияет на рекомендации

### Профиль пользователя

Для каждого пользователя накапливаем информацию о его предпочтениях:

**Предпочтения по категориям** — какие категории товаров он чаще одобряет:
- "Инструменты": 0.85 (часто лайкает)
- "Расходники": 0.70 (средне)
- "Электрика": 0.20 (редко лайкает, возможно не его профиль работ)

**Предпочтения по брендам:**
- "KNAUF": 0.90 (доверяет бренду)
- "Noname": 0.30 (не любит дешёвые бренды)

**Ценовой диапазон** — средняя цена товаров, которые он одобрял. Позволяет понять бюджет пользователя.

### Как профиль обновляется

При каждом фидбеке от пользователя:
1. Смотрим категорию и бренд оценённого товара
2. Если лайк — увеличиваем предпочтение этой категории/бренда
3. Если дизлайк — уменьшаем предпочтение
4. Обновляем средний ценовой диапазон

Используется экспоненциальное скользящее среднее, чтобы свежие оценки влияли сильнее, чем старые.

### Как профиль влияет на рекомендации

При генерации рекомендаций для конкретного пользователя:
- Товары из его любимых категорий получают буст (множитель 1.2-1.5)
- Товары его любимых брендов получают буст
- Товары сильно дороже его обычного бюджета получают штраф (множитель 0.7)

Это позволяет двум пользователям, смотрящим один и тот же товар, получать разные рекомендации.

---

## Полный алгоритм генерации рекомендаций

Вот как все компоненты работают вместе:

```python
def get_recommendations(main_product_id, user_id=None):
    # ШАГ 1: Получаем кандидатов через эмбеддинги (Ollama + FAISS)
    # Это ХОЛОДНЫЙ СТАРТ — работает всегда, даже без фидбека
    main_embedding = get_embedding(main_product_id)
    candidates = faiss_index.search(main_embedding, k=100)

    # ШАГ 2: Фильтруем по правилам категорий
    candidates = filter_by_category_rules(main_product_id, candidates)

    # ШАГ 3: Применяем ГЛОБАЛЬНЫЙ фидбек (от всех пользователей)
    for candidate in candidates:
        stats = get_feedback_stats(main_product_id, candidate.id)

        if stats.total > 0:
            # Есть статистика — используем её
            feedback_score = (stats.positive + 1) / (stats.total + 2)  # сглаживание
        else:
            # Нет статистика — нейтральный скор
            feedback_score = 0.5

        candidate.score *= feedback_score * 2  # превращаем 0-1 в 0-2 множитель

    # ШАГ 4: Применяем ПЕРСОНАЛЬНЫЕ предпочтения (если есть user_id)
    if user_id:
        profile = get_user_profile(user_id)

        if profile:
            for candidate in candidates:
                # Буст если категория нравится юзеру
                cat_pref = profile.preferred_categories.get(candidate.category, 0.5)
                candidate.score *= (0.5 + cat_pref)  # 0.5-1.5 множитель

                # Буст если бренд нравится
                brand_pref = profile.preferred_brands.get(candidate.brand, 0.5)
                candidate.score *= (0.7 + brand_pref * 0.6)  # 0.7-1.3 множитель

    # ШАГ 5: Сортируем и возвращаем топ-20
    candidates.sort(key=lambda x: x.score, reverse=True)
    return candidates[:20]
```

### Разбор по шагам

**Шаг 1** — находим 100 товаров, семантически близких к основному. Это грубый отбор кандидатов.

**Шаг 2** — убираем аналоги, оставляем сопутствующие. После этого шага остаётся 20-50 кандидатов.

**Шаг 3** — применяем коллективный разум. Если другие пользователи массово говорили "этот шпатель не подходит к этой штукатурке", он уйдёт вниз.

**Шаг 4** — персонализируем под конкретного пользователя. Его предпочтения по брендам и категориям влияют на порядок.

**Шаг 5** — берём лучшие 20 и возвращаем.

---

## Эволюция системы: от холодного старта к персонализации

### День 1 (холодный старт)

**Ситуация:** Нет никакого фидбека, профили пользователей пустые.

**Источники ранжирования:**
- Эмбеддинги (Ollama): 100% влияния
- Правила категорий: бинарный фильтр (да/нет)
- Глобальный фидбек: нет данных → нейтрально (множитель 1.0)
- Персональный профиль: нет данных → нейтрально (множитель 1.0)

**Результат:** Базовые рекомендации на основе семантической близости и экспертных правил. Качество приемлемое, но не персонализированное.

### День 7 (накопился глобальный фидбек)

**Ситуация:** 500 пользователей оценили рекомендации, накопилась статистика для популярных товаров.

**Пример статистики для "Штукатурка KNAUF Ротбанд":**
- Шпатель фасадный 350мм: 45 лайков, 5 дизлайков → 90% одобрения
- Шпатель узкий 50мм: 10 лайков, 35 дизлайков → 22% одобрения
- Грунтовка KNAUF: 89 лайков, 5 дизлайков → 95% одобрения

**Источники ранжирования:**
- Эмбеддинги (Ollama): ~40% влияния
- Правила категорий: бинарный фильтр
- Глобальный фидбек: ~60% влияния (теперь работает!)
- Персональный профиль: минимальное влияние

**Результат:** Шпатель фасадный и грунтовка KNAUF вверху выдачи. Узкий шпатель внизу или исчез (видимо, пользователи считают его неподходящим для штукатурки).

### День 30 (персонализация работает)

**Ситуация:** Конкретный пользователь #123 активно использовал систему и накопил профиль.

**Профиль пользователя #123:**
- Любит бренд KNAUF (90% одобрения товаров этого бренда)
- Не любит дешёвые noname бренды (30% одобрения)
- Предпочитает категорию "Инструменты" (85%)
- Средний бюджет: 1500 руб. за товар

**Источники ранжирования для пользователя #123:**
- Эмбеддинги (Ollama): ~30% влияния
- Правила категорий: бинарный фильтр
- Глобальный фидбек: ~40% влияния
- Персональный профиль: ~30% влияния (персонализация!)

**Результат:** Этот пользователь видит товары KNAUF выше, noname бренды ниже, больше инструментов в выдаче. Другой пользователь с другим профилем увидит другой порядок.

---

## Опционально: ML-модель ранжирования

Описанный выше подход (счётчики + профили) достаточен для хакатона и работает хорошо. Но если хочется добавить "настоящий ML" для впечатления жюри, можно обучить модель ранжирования.

### Идея

Вместо ручных формул с множителями обучаем классификатор, который предсказывает вероятность положительного фидбека.

### Данные для обучения

Каждый фидбек превращается в обучающий пример:

**Признаки (features):**
- Семантическая близость (из эмбеддингов)
- Совпадение категорий (бинарный признак)
- Разница в цене
- Совпадение бренда
- Категория основного товара (one-hot encoding)
- Категория рекомендованного товара (one-hot encoding)
- Предпочтения пользователя по категориям (если есть)

**Целевая переменная:**
- 1 если пользователь нажал "подошёл"
- 0 если нажал "не подошёл"

### Модель

Подходят простые и интерпретируемые модели:
- LightGBM
- CatBoost
- Логистическая регрессия

Обучение происходит офлайн, раз в сутки или реже, на всех накопленных данных.

### Применение

При генерации рекомендаций:
1. Для каждого кандидата собираем признаки
2. Прогоняем через модель, получаем вероятность
3. Сортируем кандидатов по вероятности
4. Возвращаем топ-20

### Когда это нужно

ML-модель имеет смысл когда:
- Накопилось много данных (тысячи фидбеков)
- Ручные формулы перестают справляться
- Хочется автоматически находить сложные паттерны

Для MVP и демонстрации на хакатоне статистического подхода достаточно.

---

## Структура данных и таблицы

### Таблица товаров (products)

| Поле | Тип | Описание |
|------|-----|----------|
| id | INT | Уникальный идентификатор |
| name | VARCHAR | Название товара |
| description | TEXT | Описание |
| category_id | INT | Ссылка на категорию |
| brand | VARCHAR | Бренд |
| price | DECIMAL | Цена |
| embedding | VECTOR(768) | Эмбеддинг от Ollama |

### Таблица категорий (categories)

| Поле | Тип | Описание |
|------|-----|----------|
| id | INT | Уникальный идентификатор |
| name | VARCHAR | Название категории |
| parent_id | INT | Родительская категория |
| stage | VARCHAR | Этап ремонта (white_box, black_box, finishing) |

### Таблица правил совместимости (category_rules)

| Поле | Тип | Описание |
|------|-----|----------|
| main_category_id | INT | Основная категория |
| compatible_category_id | INT | Совместимая категория |
| weight | FLOAT | Вес связи (опционально) |

### Таблица сырого фидбека (feedback)

| Поле | Тип | Описание |
|------|-----|----------|
| id | INT | Уникальный идентификатор |
| user_id | INT | ID пользователя |
| main_product_id | INT | ID основного товара |
| recommended_product_id | INT | ID рекомендованного товара |
| feedback_type | ENUM | 'positive' / 'negative' |
| created_at | TIMESTAMP | Время оценки |

### Таблица агрегированной статистики (feedback_stats)

| Поле | Тип | Описание |
|------|-----|----------|
| main_product_id | INT | ID основного товара |
| recommended_product_id | INT | ID рекомендованного товара |
| positive_count | INT | Количество положительных оценок |
| negative_count | INT | Количество отрицательных оценок |

### Таблица профилей пользователей (user_profiles)

| Поле | Тип | Описание |
|------|-----|----------|
| user_id | INT | ID пользователя |
| preferred_categories | JSONB | {"Шпатели": 0.8, "Грунтовки": 0.9} |
| preferred_brands | JSONB | {"KNAUF": 0.7, "Ceresit": 0.5} |
| avg_price_preference | DECIMAL | Средняя цена одобренных товаров |
| updated_at | TIMESTAMP | Время последнего обновления |

---

## Вопросы для обсуждения

1. **Модель эмбеддингов** — какую модель Ollama выбрать? nomic-embed-text vs mxbai-embed-large vs другие?

2. **Формирование текста для эмбеддинга** — какие поля товара включать? Как форматировать?

3. **Правила категорий** — откуда брать? Составлять вручную или пытаться извлечь из данных?

4. **Баланс факторов** — какие веса давать разным компонентам (эмбеддинги vs фидбек vs профиль)?

5. **Exploration** — нужно ли добавлять случайные рекомендации для исследования новых связей?

6. **ML-модель** — стоит ли её делать или статистического подхода достаточно для хакатона?
